{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Llama 2: Prompt Engineering Expirements to Extract Information\n",
    "\n",
    "This notebook documents expirements with Llama 2 prompts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, time, os, json\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import display, HTML\n",
    "from sqlmodel import SQLModel, Field, ARRAY, Float, JSON, Relationship\n",
    "from typing import Optional, List, Dict\n",
    "from sqlalchemy import Column\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4f0cd2efebc9c13435455e28dee741fdef5188697d93e57e0618d8c9f414d9f2\n"
     ]
    }
   ],
   "source": [
    "# To use Llama 2 70B on HuggingFace requires an authentication token and HuggingFace Pro account that cost $9 a month.  \n",
    "# To learn more see \n",
    "# - https://huggingface.co/meta-llama/Llama-2-70b-chat-hf?inference_api=true\n",
    "# - https://huggingface.co/pricing\n",
    "\n",
    "# Loading authentication token from .env file\n",
    "load_dotenv('../.env')\n",
    "together_token = os.getenv(\"TOGETHER_TOKEN\")\n",
    "print(together_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class Entity(BaseModel):\n",
    "    name: Optional[str]\n",
    "    type: Optional[str]\n",
    "    explanation: Optional[str]\n",
    "\n",
    "class ConceptIdea(BaseModel):\n",
    "    concept: Optional[str] = Field(default=None)\n",
    "    explanation: Optional[str] = Field(default=None)\n",
    "    \n",
    "\n",
    "class DocumentInfo(BaseModel):\n",
    "    oneSentenceSummary: Optional[str]\n",
    "    summaryInNumericBulletPoints: Optional[List[str]]\n",
    "    \n",
    "    entities: Optional[List[Entity]]\n",
    "    concepts_ideas: Optional[List[ConceptIdea]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generalize methods and class that will be used in the expirements below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object to represent an answer from Llama\n",
    "class Answer:\n",
    "    def __init__(self, answer, elapse):\n",
    "        self.answer = answer\n",
    "        self.elapse = elapse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "A first intro to Complex RAG (Retrieval Augmented Generation)\n",
    "Chia Jeng Yang\n",
    "Enterprise RAG\n",
    "\n",
    "If you’re looking for a non-technical introduction to RAG, including answers to various getting-started questions and a discussion of relevant use-cases, check out our breakdown of RAG here.\n",
    "In this article, we discuss various technical considerations when implementing RAG, exploring the concepts of chunking, query augmentation, hierarchies, multi-hop reasoning, and knowledge graphs. We also discuss unsolved problems & opportunities in the RAG infrastructure space, and introduce some infrastructure solutions for building RAG pipelines.\n",
    "The first obstacles and design choices you will be making when building a RAG system are in how to prepare the documents for storage and information extraction. That will be the primary focus of this article.\n",
    "As a refresher, here’s an overview of a RAG system architecture.\n",
    "Relevance vs Similarity\n",
    "When discussing effective information retrieval in RAG, it is crucial to understand the difference between “relevance” and “similarity.” Whereas similarity is about the similarity in words matching, relevance is about the connectedness of ideas. You can identify semantically close content using a vector database query, but identifying and retrieving relevant content requires more sophisticated tooling.\n",
    "This is an important concept to keep in mind as we explore various RAG techniques below. If you haven’t yet, you should check out Llamaindex’s helpful video on building production RAG apps. This is a good primer for our discussion on various RAG system development techniques.\n",
    "\n",
    "Chunking Strategy\n",
    "In the context of natural language processing, “chunking” refers to the segmentation of text into small, concise, meaningful ‘chunks.’ A RAG system can more quickly and accurately locate relevant context in smaller text chunks than in large documents.\n",
    "How can you ensure you’re selecting the right chunk? The effectiveness of your chunking strategy largely depends on the quality and structure of these chunks.\n",
    "Determining the optimal chunk size is about striking a balance — capturing all essential information without sacrificing speed.\n",
    "While larger chunks can capture more context, they introduce more noise and require more time and compute costs to process. Smaller chunks have less noise, but may not fully capture the necessary context. Overlapping chunks is a way to balance both of these constraints. By overlapping chunks, a query will likely retrieve enough relevant data across multiple vectors in order to generate a properly contextualized response.\n",
    "One limitation is that this strategy assumes that all of the information you must retrieve can be found in a single document. If the required context is split across multiple different documents, you may want to consider leveraging solutions like document hierarchies and knowledge graphs.\n",
    "\n",
    "Document Hierarchies\n",
    "A document hierarchy is a powerful way of organizing your data to improve information retrieval. You can think of a document hierarchy as a table of contents for your RAG system. It organizes chunks in a structured manner that allows RAG systems to efficiently retrieve and process relevant, related data. Document hierarchies play a crucial role in the effectiveness of RAG by helping the LLM decide which chunks contain the most relevant data to extract.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "A first intro to Complex RAG (Retrieval Augmented Generation)\n",
    "Chia Jeng Yang\n",
    "Enterprise RAG\n",
    "Chia Jeng Yang\n",
    "\n",
    "If you’re looking for a non-technical introduction to RAG, including answers to various getting-started questions and a discussion of relevant use-cases, check out our breakdown of RAG here.\n",
    "In this article, we discuss various technical considerations when implementing RAG, exploring the concepts of chunking, query augmentation, hierarchies, multi-hop reasoning, and knowledge graphs. We also discuss unsolved problems & opportunities in the RAG infrastructure space, and introduce some infrastructure solutions for building RAG pipelines.\n",
    "The first obstacles and design choices you will be making when building a RAG system are in how to prepare the documents for storage and information extraction. That will be the primary focus of this article.\n",
    "As a refresher, here’s an overview of a RAG system architecture.\n",
    "Relevance vs Similarity\n",
    "When discussing effective information retrieval in RAG, it is crucial to understand the difference between “relevance” and “similarity.” Whereas similarity is about the similarity in words matching, relevance is about the connectedness of ideas. You can identify semantically close content using a vector database query, but identifying and retrieving relevant content requires more sophisticated tooling.\n",
    "This is an important concept to keep in mind as we explore various RAG techniques below. If you haven’t yet, you should check out Llamaindex’s helpful video on building production RAG apps. This is a good primer for our discussion on various RAG system development techniques.\n",
    "\n",
    "Chunking Strategy\n",
    "In the context of natural language processing, “chunking” refers to the segmentation of text into small, concise, meaningful ‘chunks.’ A RAG system can more quickly and accurately locate relevant context in smaller text chunks than in large documents.\n",
    "How can you ensure you’re selecting the right chunk? The effectiveness of your chunking strategy largely depends on the quality and structure of these chunks.\n",
    "Determining the optimal chunk size is about striking a balance — capturing all essential information without sacrificing speed.\n",
    "While larger chunks can capture more context, they introduce more noise and require more time and compute costs to process. Smaller chunks have less noise, but may not fully capture the necessary context. Overlapping chunks is a way to balance both of these constraints. By overlapping chunks, a query will likely retrieve enough relevant data across multiple vectors in order to generate a properly contextualized response.\n",
    "One limitation is that this strategy assumes that all of the information you must retrieve can be found in a single document. If the required context is split across multiple different documents, you may want to consider leveraging solutions like document hierarchies and knowledge graphs.\n",
    "\n",
    "Document Hierarchies\n",
    "A document hierarchy is a powerful way of organizing your data to improve information retrieval. You can think of a document hierarchy as a table of contents for your RAG system. It organizes chunks in a structured manner that allows RAG systems to efficiently retrieve and process relevant, related data. Document hierarchies play a crucial role in the effectiveness of RAG by helping the LLM decide which chunks contain the most relevant data to extract.\n",
    "\n",
    "If you’re looking for a non-technical introduction to RAG, including answers to various getting-started questions and a discussion of relevant use-cases, check out our breakdown of RAG here.\n",
    "In this article, we discuss various technical considerations when implementing RAG, exploring the concepts of chunking, query augmentation, hierarchies, multi-hop reasoning, and knowledge graphs. We also discuss unsolved problems & opportunities in the RAG infrastructure space, and introduce some infrastructure solutions for building RAG pipelines.\n",
    "The first obstacles and design choices you will be making when building a RAG system are in how to prepare the documents for storage and information extraction. That will be the primary focus of this article.\n",
    "As a refresher, here’s an overview of a RAG system architecture.\n",
    "Relevance vs Similarity\n",
    "When discussing effective information retrieval in RAG, it is crucial to understand the difference between “relevance” and “similarity.” Whereas similarity is about the similarity in words matching, relevance is about the connectedness of ideas. You can identify semantically close content using a vector database query, but identifying and retrieving relevant content requires more sophisticated tooling.\n",
    "This is an important concept to keep in mind as we explore various RAG techniques below. If you haven’t yet, you should check out Llamaindex’s helpful video on building production RAG apps. This is a good primer for our discussion on various RAG system development techniques.\n",
    "\n",
    "Chunking Strategy\n",
    "In the context of natural language processing, “chunking” refers to the segmentation of text into small, concise, meaningful ‘chunks.’ A RAG system can more quickly and accurately locate relevant context in smaller text chunks than in large documents.\n",
    "How can you ensure you’re selecting the right chunk? The effectiveness of your chunking strategy largely depends on the quality and structure of these chunks.\n",
    "Determining the optimal chunk size is about striking a balance — capturing all essential information without sacrificing speed.\n",
    "While larger chunks can capture more context, they introduce more noise and require more time and compute costs to process. Smaller chunks have less noise, but may not fully capture the necessary context. Overlapping chunks is a way to balance both of these constraints. By overlapping chunks, a query will likely retrieve enough relevant data across multiple vectors in order to generate a properly contextualized response.\n",
    "One limitation is that this strategy assumes that all of the information you must retrieve can be found in a single document. If the required context is split across multiple different documents, you may want to consider leveraging solutions like document hierarchies and knowledge graphs.\n",
    "\n",
    "Document Hierarchies\n",
    "A document hierarchy is a powerful way of organizing your data to improve information retrieval. You can think of a document hierarchy as a table of contents for your RAG system. It organizes chunks in a structured manner that allows RAG systems to efficiently retrieve and process relevant, related data. Document hierarchies play a crucial role in the effectiveness of RAG by helping the LLM decide which chunks contain the most relevant data to extract.\n",
    "\n",
    "If you’re looking for a non-technical introduction to RAG, including answers to various getting-started questions and a discussion of relevant use-cases, check out our breakdown of RAG here.\n",
    "In this article, we discuss various technical considerations when implementing RAG, exploring the concepts of chunking, query augmentation, hierarchies, multi-hop reasoning, and knowledge graphs. We also discuss unsolved problems & opportunities in the RAG infrastructure space, and introduce some infrastructure solutions for building RAG pipelines.\n",
    "The first obstacles and design choices you will be making when building a RAG system are in how to prepare the documents for storage and information extraction. That will be the primary focus of this article.\n",
    "As a refresher, here’s an overview of a RAG system architecture.\n",
    "Relevance vs Similarity\n",
    "When discussing effective information retrieval in RAG, it is crucial to understand the difference between “relevance” and “similarity.” Whereas similarity is about the similarity in words matching, relevance is about the connectedness of ideas. You can identify semantically close content using a vector database query, but identifying and retrieving relevant content requires more sophisticated tooling.\n",
    "This is an important concept to keep in mind as we explore various RAG techniques below. If you haven’t yet, you should check out Llamaindex’s helpful video on building production RAG apps. This is a good primer for our discussion on various RAG system development techniques.\n",
    "\n",
    "Chunking Strategy\n",
    "In the context of natural language processing, “chunking” refers to the segmentation of text into small, concise, meaningful ‘chunks.’ A RAG system can more quickly and accurately locate relevant context in smaller text chunks than in large documents.\n",
    "How can you ensure you’re selecting the right chunk? The effectiveness of your chunking strategy largely depends on the quality and structure of these chunks.\n",
    "Determining the optimal chunk size is about striking a balance — capturing all essential information without sacrificing speed.\n",
    "While larger chunks can capture more context, they introduce more noise and require more time and compute costs to process. Smaller chunks have less noise, but may not fully capture the necessary context. Overlapping chunks is a way to balance both of these constraints. By overlapping chunks, a query will likely retrieve enough relevant data across multiple vectors in order to generate a properly contextualized response.\n",
    "One limitation is that this strategy assumes that all of the information you must retrieve can be found in a single document. If the required context is split across multiple different documents, you may want to consider leveraging solutions like document hierarchies and knowledge graphs.\n",
    "\n",
    "Document Hierarchies\n",
    "A document hierarchy is a powerful way of organizing your data to improve information retrieval. You can think of a document hierarchy as a table of contents for your RAG system. It organizes chunks in a structured manner that allows RAG systems to efficiently retrieve and process relevant, related data. Document hierarchies play a crucial role in the effectiveness of RAG by helping the LLM decide which chunks contain the most relevant data to extract.\n",
    "\n",
    "If you’re looking for a non-technical introduction to RAG, including answers to various getting-started questions and a discussion of relevant use-cases, check out our breakdown of RAG here.\n",
    "In this article, we discuss various technical considerations when implementing RAG, exploring the concepts of chunking, query augmentation, hierarchies, multi-hop reasoning, and knowledge graphs. We also discuss unsolved problems & opportunities in the RAG infrastructure space, and introduce some infrastructure solutions for building RAG pipelines.\n",
    "The first obstacles and design choices you will be making when building a RAG system are in how to prepare the documents for storage and information extraction. That will be the primary focus of this article.\n",
    "As a refresher, here’s an overview of a RAG system architecture.\n",
    "Relevance vs Similarity\n",
    "When discussing effective information retrieval in RAG, it is crucial to understand the difference between “relevance” and “similarity.” Whereas similarity is about the similarity in words matching, relevance is about the connectedness of ideas. You can identify semantically close content using a vector database query, but identifying and retrieving relevant content requires more sophisticated tooling.\n",
    "This is an important concept to keep in mind as we explore various RAG techniques below. If you haven’t yet, you should check out Llamaindex’s helpful video on building production RAG apps. This is a good primer for our discussion on various RAG system development techniques.\n",
    "\n",
    "Chunking Strategy\n",
    "In the context of natural language processing, “chunking” refers to the segmentation of text into small, concise, meaningful ‘chunks.’ A RAG system can more quickly and accurately locate relevant context in smaller text chunks than in large documents.\n",
    "How can you ensure you’re selecting the right chunk? The effectiveness of your chunking strategy largely depends on the quality and structure of these chunks.\n",
    "Determining the optimal chunk size is about striking a balance — capturing all essential information without sacrificing speed.\n",
    "While larger chunks can capture more context, they introduce more noise and require more time and compute costs to process. Smaller chunks have less noise, but may not fully capture the necessary context. Overlapping chunks is a way to balance both of these constraints. By overlapping chunks, a query will likely retrieve enough relevant data across multiple vectors in order to generate a properly contextualized response.\n",
    "One limitation is that this strategy assumes that all of the information you must retrieve can be found in a single document. If the required context is split across multiple different documents, you may want to consider leveraging solutions like document hierarchies and knowledge graphs.\n",
    "\n",
    "Document Hierarchies\n",
    "A document hierarchy is a powerful way of organizing your data to improve information retrieval. You can think of a document hierarchy as a table of contents for your RAG system. It organizes chunks in a structured manner that allows RAG systems to efficiently retrieve and process relevant, related data. Document hierarchies play a crucial role in the effectiveness of RAG by helping the LLM decide which chunks contain the most relevant data to extract.\n",
    "\n",
    "If you’re looking for a non-technical introduction to RAG, including answers to various getting-started questions and a discussion of relevant use-cases, check out our breakdown of RAG here.\n",
    "In this article, we discuss various technical considerations when implementing RAG, exploring the concepts of chunking, query augmentation, hierarchies, multi-hop reasoning, and knowledge graphs. We also discuss unsolved problems & opportunities in the RAG infrastructure space, and introduce some infrastructure solutions for building RAG pipelines.\n",
    "The first obstacles and design choices you will be making when building a RAG system are in how to prepare the documents for storage and information extraction. That will be the primary focus of this article.\n",
    "As a refresher, here’s an overview of a RAG system architecture.\n",
    "Relevance vs Similarity\n",
    "When discussing effective information retrieval in RAG, it is crucial to understand the difference between “relevance” and “similarity.” Whereas similarity is about the similarity in words matching, relevance is about the connectedness of ideas. You can identify semantically close content using a vector database query, but identifying and retrieving relevant content requires more sophisticated tooling.\n",
    "This is an important concept to keep in mind as we explore various RAG techniques below. If you haven’t yet, you should check out Llamaindex’s helpful video on building production RAG apps. This is a good primer for our discussion on various RAG system development techniques.\n",
    "\n",
    "Chunking Strategy\n",
    "In the context of natural language processing, “chunking” refers to the segmentation of text into small, concise, meaningful ‘chunks.’ A RAG system can more quickly and accurately locate relevant context in smaller text chunks than in large documents.\n",
    "How can you ensure you’re selecting the right chunk? The effectiveness of your chunking strategy largely depends on the quality and structure of these chunks.\n",
    "Determining the optimal chunk size is about striking a balance — capturing all essential information without sacrificing speed.\n",
    "While larger chunks can capture more context, they introduce more noise and require more time and compute costs to process. Smaller chunks have less noise, but may not fully capture the necessary context. Overlapping chunks is a way to balance both of these constraints. By overlapping chunks, a query will likely retrieve enough relevant data across multiple vectors in order to generate a properly contextualized response.\n",
    "One limitation is that this strategy assumes that all of the information you must retrieve can be found in a single document. If the required context is split across multiple different documents, you may want to consider leveraging solutions like document hierarchies and knowledge graphs.\n",
    "\n",
    "Document Hierarchies\n",
    "A document hierarchy is a powerful way of organizing your data to improve information retrieval. You can think of a document hierarchy as a table of contents for your RAG system. It organizes chunks in a structured manner that allows RAG systems to efficiently retrieve and process relevant, related data. Document hierarchies play a crucial role in the effectiveness of RAG by helping the LLM decide which chunks contain the most relevant data to extract.\n",
    "\n",
    "If you’re looking for a non-technical introduction to RAG, including answers to various getting-started questions and a discussion of relevant use-cases, check out our breakdown of RAG here.\n",
    "In this article, we discuss various technical considerations when implementing RAG, exploring the concepts of chunking, query augmentation, hierarchies, multi-hop reasoning, and knowledge graphs. We also discuss unsolved problems & opportunities in the RAG infrastructure space, and introduce some infrastructure solutions for building RAG pipelines.\n",
    "The first obstacles and design choices you will be making when building a RAG system are in how to prepare the documents for storage and information extraction. That will be the primary focus of this article.\n",
    "As a refresher, here’s an overview of a RAG system architecture.\n",
    "Relevance vs Similarity\n",
    "When discussing effective information retrieval in RAG, it is crucial to understand the difference between “relevance” and “similarity.” Whereas similarity is about the similarity in words matching, relevance is about the connectedness of ideas. You can identify semantically close content using a vector database query, but identifying and retrieving relevant content requires more sophisticated tooling.\n",
    "This is an important concept to keep in mind as we explore various RAG techniques below. If you haven’t yet, you should check out Llamaindex’s helpful video on building production RAG apps. This is a good primer for our discussion on various RAG system development techniques.\n",
    "\n",
    "Chunking Strategy\n",
    "In the context of natural language processing, “chunking” refers to the segmentation of text into small, concise, meaningful ‘chunks.’ A RAG system can more quickly and accurately locate relevant context in smaller text chunks than in large documents.\n",
    "How can you ensure you’re selecting the right chunk? The effectiveness of your chunking strategy largely depends on the quality and structure of these chunks.\n",
    "Determining the optimal chunk size is about striking a balance — capturing all essential information without sacrificing speed.\n",
    "While larger chunks can capture more context, they introduce more noise and require more time and compute costs to process. Smaller chunks have less noise, but may not fully capture the necessary context. Overlapping chunks is a way to balance both of these constraints. By overlapping chunks, a query will likely retrieve enough relevant data across multiple vectors in order to generate a properly contextualized response.\n",
    "One limitation is that this strategy assumes that all of the information you must retrieve can be found in a single document. If the required context is split across multiple different documents, you may want to consider leveraging solutions like document hierarchies and knowledge graphs.\n",
    "\n",
    "Document Hierarchies\n",
    "A document hierarchy is a powerful way of organizing your data to improve information retrieval. You can think of a document hierarchy as a table of contents for your RAG system. It organizes chunks in a structured manner that allows RAG systems to efficiently retrieve and process relevant, related data. Document hierarchies play a crucial role in the effectiveness of RAG by helping the LLM decide which chunks contain the most relevant data to extract.\n",
    "\n",
    "If you’re looking for a non-technical introduction to RAG, including answers to various getting-started questions and a discussion of relevant use-cases, check out our breakdown of RAG here.\n",
    "In this article, we discuss various technical considerations when implementing RAG, exploring the concepts of chunking, query augmentation, hierarchies, multi-hop reasoning, and knowledge graphs. We also discuss unsolved problems & opportunities in the RAG infrastructure space, and introduce some infrastructure solutions for building RAG pipelines.\n",
    "The first obstacles and design choices you will be making when building a RAG system are in how to prepare the documents for storage and information extraction. That will be the primary focus of this article.\n",
    "As a refresher, here’s an overview of a RAG system architecture.\n",
    "Relevance vs Similarity\n",
    "When discussing effective information retrieval in RAG, it is crucial to understand the difference between “relevance” and “similarity.” Whereas similarity is about the similarity in words matching, relevance is about the connectedness of ideas. You can identify semantically close content using a vector database query, but identifying and retrieving relevant content requires more sophisticated tooling.\n",
    "This is an important concept to keep in mind as we explore various RAG techniques below. If you haven’t yet, you should check out Llamaindex’s helpful video on building production RAG apps. This is a good primer for our discussion on various RAG system development techniques.\n",
    "\n",
    "Chunking Strategy\n",
    "In the context of natural language processing, “chunking” refers to the segmentation of text into small, concise, meaningful ‘chunks.’ A RAG system can more quickly and accurately locate relevant context in smaller text chunks than in large documents.\n",
    "How can you ensure you’re selecting the right chunk? The effectiveness of your chunking strategy largely depends on the quality and structure of these chunks.\n",
    "Determining the optimal chunk size is about striking a balance — capturing all essential information without sacrificing speed.\n",
    "While larger chunks can capture more context, they introduce more noise and require more time and compute costs to process. Smaller chunks have less noise, but may not fully capture the necessary context. Overlapping chunks is a way to balance both of these constraints. By overlapping chunks, a query will likely retrieve enough relevant data across multiple vectors in order to generate a properly contextualized response.\n",
    "One limitation is that this strategy assumes that all of the information you must retrieve can be found in a single document. If the required context is split across multiple different documents, you may want to consider leveraging solutions like document hierarchies and knowledge graphs.\n",
    "\n",
    "Document Hierarchies\n",
    "A document hierarchy is a powerful way of organizing your data to improve information retrieval. You can think of a document hierarchy as a table of contents for your RAG system. It organizes chunks in a structured manner that allows RAG systems to efficiently retrieve and process relevant, related data. Document hierarchies play a crucial role in the effectiveness of RAG by helping the LLM decide which chunks contain the most relevant data to extract.\n",
    "\n",
    "If you’re looking for a non-technical introduction to RAG, including answers to various getting-started questions and a discussion of relevant use-cases, check out our breakdown of RAG here.\n",
    "In this article, we discuss various technical considerations when implementing RAG, exploring the concepts of chunking, query augmentation, hierarchies, multi-hop reasoning, and knowledge graphs. We also discuss unsolved problems & opportunities in the RAG infrastructure space, and introduce some infrastructure solutions for building RAG pipelines.\n",
    "The first obstacles and design choices you will be making when building a RAG system are in how to prepare the documents for storage and information extraction. That will be the primary focus of this article.\n",
    "As a refresher, here’s an overview of a RAG system architecture.\n",
    "Relevance vs Similarity\n",
    "When discussing effective information retrieval in RAG, it is crucial to understand the difference between “relevance” and “similarity.” Whereas similarity is about the similarity in words matching, relevance is about the connectedness of ideas. You can identify semantically close content using a vector database query, but identifying and retrieving relevant content requires more sophisticated tooling.\n",
    "This is an important concept to keep in mind as we explore various RAG techniques below. If you haven’t yet, you should check out Llamaindex’s helpful video on building production RAG apps. This is a good primer for our discussion on various RAG system development techniques.\n",
    "\n",
    "Chunking Strategy\n",
    "In the context of natural language processing, “chunking” refers to the segmentation of text into small, concise, meaningful ‘chunks.’ A RAG system can more quickly and accurately locate relevant context in smaller text chunks than in large documents.\n",
    "How can you ensure you’re selecting the right chunk? The effectiveness of your chunking strategy largely depends on the quality and structure of these chunks.\n",
    "Determining the optimal chunk size is about striking a balance — capturing all essential information without sacrificing speed.\n",
    "While larger chunks can capture more context, they introduce more noise and require more time and compute costs to process. Smaller chunks have less noise, but may not fully capture the necessary context. Overlapping chunks is a way to balance both of these constraints. By overlapping chunks, a query will likely retrieve enough relevant data across multiple vectors in order to generate a properly contextualized response.\n",
    "One limitation is that this strategy assumes that all of the information you must retrieve can be found in a single document. If the required context is split across multiple different documents, you may want to consider leveraging solutions like document hierarchies and knowledge graphs.\n",
    "\n",
    "Document Hierarchies\n",
    "A document hierarchy is a powerful way of organizing your data to improve information retrieval. You can think of a document hierarchy as a table of contents for your RAG system. It organizes chunks in a structured manner that allows RAG systems to efficiently retrieve and process relevant, related data. Document hierarchies play a crucial role in the effectiveness of RAG by helping the LLM decide which chunks contain the most relevant data to extract.\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content = \"\"\"You are a researcher task with answering questions about an article.  \n",
    "        Please ensure that your responses are socially unbiased and positive in nature.\n",
    "        If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. \n",
    "        If you don't know the answer, please don't share false information.\"\"\"\n",
    "        \n",
    "user_content_1 = \"\"\"Answers output must confirm to the this JSON format [/INST] \n",
    "\n",
    "        JSON Output: {{\n",
    "        \"oneSentenceSummary\" : \"Mobile game soft launch is a process of releasing a game to a limited audience for testing.\",\n",
    "        \"summaryInNumericBulletPoints\" : [\n",
    "        \"1. Mobile game soft launch is a process of releasing a game to a limited audience for testing.\",\n",
    "        \"2. Mobile game soft launch is a process of releasing a game to a limited audience for testing.\",\n",
    "        ],\n",
    "        \"entities\" : [\n",
    "        {{\"name\": \"semiconductor\", \"type\": \"industry\", \"explanation\": \"Companies engaged in the design and fabrication of semiconductors and semiconductor devices\"}},\n",
    "        {{\"name\": \"NBA\", \"type\": \"sport league\", \"explanation\": \"NBA is the national basketball league\"}},\n",
    "        {{\"name\": \"Ford F150\", \"type\": \"vehicle\", \"explanation\": \"Article talks about the Ford F150 truck\"}},\n",
    "        ],\n",
    "        \"concepts_ideas\": [\n",
    "            {{\"concept\": \"mobile game soft launch\", \"explanation\": \"Mobile game soft launch is a process of releasing a game to a limited audience for testing.\"}},\n",
    "            {{\"concept\": \"US Civil War\", \"explanation\": \"The American Civil War was a civil war in the United States between the Union and the Confederacy, which had been formed by states that had seceded from the Union. The central cause of the war was the dispute over whether slavery would be permitted to expand into the western territories, leading to more slave states, or be prevented from doing so, which many believed would place slavery on a course of ultimate extinction.\"}},\n",
    "            {{\"concet\": \"Capitalism\", \"explanation\": Capitalism is an economic system based on the private ownership of the means of production and their operation for profit. Central characteristics of capitalism include capital accumulation, competitive markets, price system, private property, property rights recognition, voluntary exchange, and wage labor.\"}}    \n",
    "        ] \n",
    "        }}\"\"\"\n",
    "user_content_2 = \"\"\"Use the examples above to answer the following questions.\n",
    "        1. Summarize the article in one sentence. Limit the answer to twenty words.\n",
    "        2. Summarize the article in multiple bullet-points. Each bullet-point need to have betweeen ten to tweenty words. Limit the number of bullet points must below six.\n",
    "        3. Identify ten entities (companies, people, location, products....) mentioned in the article. Include short explanation for each entity.\n",
    "        4. Identify three concepts or ideas mentioned in the article. Include short explanation for each concept or idea.\n",
    "\n",
    "        Use the JSON format above to output your answer. Only output valid JSON format.\"\"\"\n",
    "        \n",
    "user_content_3 = \"\"\"Article: {BODY}\"\"\".format(BODY=text)\n",
    "\n",
    "client = openai.OpenAI(\n",
    "    api_key=together_token,\n",
    "    base_url=\"https://api.together.xyz/v1\",\n",
    "    )\n",
    "chat_completion = client.chat.completions.create(\n",
    "    model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
    "    response_format={\"type\": \"json_object\", \"schema\": DocumentInfo.model_json_schema()},\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_content},\n",
    "        {\"role\": \"user\", \"content\": user_content_1},\n",
    "        {\"role\": \"user\", \"content\": user_content_2},\n",
    "        {\"role\": \"user\", \"content\": user_content_3},\n",
    "    ],\n",
    "    temperature=0.2,\n",
    "    max_tokens=1024,\n",
    "    top_p=0.8,\n",
    "    frequency_penalty=1.0,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Together response:\n",
      "  {\n",
      "\"oneSentenceSummary\" : \"This article discusses various technical considerations when implementing Retrieval Augmented Generation (RAG) systems, including chunking strategy, document hierarchies, and the difference between relevance and similarity in information retrieval\",\n",
      "\"summaryInNumericBulletPoints\" : [\n",
      "\"1. The article discusses the importance of understanding the difference between 'relevance' and 'similarity' in effective information retrieval for RAG systems\",\n",
      "\"2. The article introduces the concept of 'chunking' in natural language processing, which involves segmenting text into small, concise, meaningful chunks for faster and more accurate information retrieval\",\n",
      "\"3. The effectiveness of the chunking strategy depends on the quality and structure of the chunks, and determining the optimal chunk size is about striking a balance between capturing essential information and reducing noise\",\n",
      "\"4. Document hierarchies are a powerful way of organizing data to improve information retrieval in RAG systems, acting as a table of contents for the system and helping the LLM decide which chunks contain the most relevant data\",\n",
      "\"5. The article highlights the importance of understanding unsolved problems and opportunities in the RAG infrastructure space, and introduces some infrastructure solutions for building RAG pipelines\"\n",
      "],\n",
      "\"entities\" : [\n",
      "{\"name\": \"RAG\", \"type\": \"technology\", \"explanation\": \"Retrieval Augmented Generation (RAG) is a technology used for information retrieval\"},\n",
      "{\"name\": \"chunking\", \"type\": \"technique\", \"explanation\": \"Chunking is a technique used in natural language processing to segment text into small, concise, meaningful chunks\"},\n",
      "{\"name\": \"document hierarchies\", \"type\": \"technique\", \"explanation\": \"Document hierarchies are a technique used in RAG systems to organize data in a structured manner for efficient information retrieval\"},\n",
      "{\"name\": \"LLM\", \"type\": \"technology\", \"explanation\": \"LLM is a technology used in RAG systems for language modeling\"},\n",
      "{\"name\": \"vector database query\", \"type\": \"technology\", \"explanation\": \"A vector database query is a technology used for identifying semantically close content\"},\n",
      "{\"name\": \"Llamaindex\", \"type\": \"company\", \"explanation\": \"Llamaindex is a company that provides helpful videos on building production RAG apps\"},\n",
      "{\"name\": \"similarity\", \"type\": \"concept\", \"explanation\": \"Similarity is a concept used in information retrieval to measure the similarity in words matching\"},\n",
      "{\"name\": \"relevance\", \"type\": \"concept\", \"explanation\": \"Relevance is a concept used in information retrieval to measure the connectedness of ideas\"},\n",
      "{\"name\": \"infrastructure solutions\", \"type\": \"technology\", \"explanation\": \"Infrastructure solutions are technologies used for building RAG pipelines\"},\n",
      "{\"name\": \"information retrieval\", \"type\": \"concept\", \"explanation\": \"Information retrieval is the process of searching for and retrieving information from a database, document, or other information repository\"}\n",
      "],\n",
      "\"concepts_ideas\": [\n",
      "{\"concept\": \"RAG system architecture\", \"explanation\": \"RAG system architecture refers to the design and structure of a Retrieval Augmented Generation system\"},\n",
      "{\"concept\": \"Relevance vs Similarity\", \"explanation\": \"Relevance and similarity are two important concepts in information retrieval, with relevance being about the connectedness of ideas and similarity being about the similarity in words matching\"},\n",
      "{\"concept\": \"Chunking Strategy\", \"explanation\": \"Chunking strategy is a technique used in natural language processing to segment text into small, concise, meaningful chunks for faster and more accurate information retrieval\"}\n",
      "]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = chat_completion.choices[0].message.content\n",
    "print(\"Together response:\\n\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ConceptIdea(concept='RAG system architecture', explanation='RAG system architecture refers to the design and structure of a Retrieval Augmented Generation system'),\n",
       " ConceptIdea(concept='Relevance vs Similarity', explanation='Relevance and similarity are two important concepts in information retrieval, with relevance being about the connectedness of ideas and similarity being about the similarity in words matching'),\n",
       " ConceptIdea(concept='Chunking Strategy', explanation='Chunking strategy is a technique used in natural language processing to segment text into small, concise, meaningful chunks for faster and more accurate information retrieval')]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "di = DocumentInfo.model_validate_json(chat_completion.choices[0].message.content)\n",
    "di.concepts_ideas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"  #  \"togethercomputer/llama-2-13b-chat\"\n",
    "\n",
    "def together_generate(prompt, temperature = 0.2, top_p = 0.8, top_k = 70) -> str:\n",
    "\n",
    "    URL = \"https://api.together.xyz/inference\"\n",
    "    \n",
    "    #  \"stop\": \".\",\n",
    "    payload = {\n",
    "        \"model\": \"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
    "        \"prompt\": prompt,\n",
    "        \"max_tokens\": 1000,\n",
    "        \"temperature\": temperature,\n",
    "        \"top_p\": top_p,\n",
    "        \"top_k\": top_k,\n",
    "        \"repetition_penalty\": 1,\n",
    "    }\n",
    "    headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"content-type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {together_token}\",\n",
    "        \"User-Agent\": \"Acme Benchmark\",\n",
    "    }\n",
    "\n",
    "    response = requests.post(URL, json=payload, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(response.status_code)\n",
    "        print(response.text)\n",
    "        return response.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper function that run generate and return an Answer\n",
    "def run_prompt(prompt: str, temperature = 0.2, top_p = 0.8, top_k = 70) -> Answer:\n",
    "    start_time = time.time()\n",
    "    res = together_generate(prompt)\n",
    "    answer = res['output']['choices'][0]['text']\n",
    "    end_time = time.time()\n",
    "    elapse = round(end_time - start_time)\n",
    "    return Answer(answer, elapse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display answer object in HTML\n",
    "def display_answer(answer: Answer, header = ''):\n",
    "    answer_html_template = \"\"\"<h3>{HEADER} Answer - Time to Generate: {ELAPSE} seconds</h3>\n",
    "    <textarea cols='100' rows={NUM_ROWS}>{ANSWER}</textarea>\"\"\"\n",
    "    \n",
    "    number_rows = (len(answer.answer.split(' ')) / 10)\n",
    "    \n",
    "    html = answer_html_template.format(ANSWER=answer.answer, ELAPSE=answer.elapse, HEADER=header, NUM_ROWS=number_rows)\n",
    "    display(HTML(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Expirements Focus\n",
    "The expirements will be focused on extracting information from a blogpost from Addresson Horoviz about mobile games soft launch. Since the Llama have size limit of tokens a subset of the post is used.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "cwd = cwd.replace('/notebooks', '')\n",
    "directory = os.path.join(cwd, \"tests/data/\")\n",
    "\n",
    "def read_txt_files(directory):\n",
    "    txt_files = []\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith(\".txt\"):\n",
    "            file_path = os.path.join(directory, file)\n",
    "            with open(file_path, \"r\") as f:\n",
    "                txt_files.append(f.read())\n",
    "    return txt_files\n",
    "\n",
    "text_files = read_txt_files(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3> Answer - Time to Generate: 5 seconds</h3>\n",
       "    <textarea cols='100' rows=24.2>and 'The Irishman'\n",
       "- Richard Romanus, actor in Mean Streets, dies at 80\n",
       "- Known for his role as Michael Longo, a loan shark in Little Italy\n",
       "- Handled prominent voice roles for Ralph Bakshi in Wizards and Hey Good Lookin'\n",
       "- Appeared on four episodes of The Sopranos as Richard LaPenna\n",
       "- Son of a dentist, born in Barre, Vermont, and raised in West Hartford, Connecticut\n",
       "- Graduated from Xavier University in Cincinnati in 1964 with a degree in philosophy\n",
       "- Spent a year in law school before studying acting with Lee Strasberg at Carnegie Hall\n",
       "- Appeared on episodes of Mission: Impossible and The Mod Squad and in the David Janssen-starring telefilm Night Chase before he was hired on Mean Streets\n",
       "- Spent the rest of the decade showing up on such shows as Rhoda, Kojak, Starsky & Hutch, The Rockford Files and Hawaii Five-O and in the film Russian Roulette (1975)\n",
       "- Played another cop on another short-lived ABC series, Foul Play, in 1981\n",
       "- Survivors include his second wife, Oscar-nominated costume designer Anthea Sylbert, whom he married in August 1985, and younger brother Robert Romanus, who played Mike Damone in Fast Times at Ridgemont High\n",
       "- Moved to the Greek town of Skiathos in 1998 and wrote about the experience in Act III: A Small Island in the Aegean, published in 2011\n",
       "- Authored two novels set in the country, 2011's Chrysalis and 2014's Matoula's Echo\n",
       "- First wife was actress-singer Tina Bohlmann. They were married from 1967 until their 1975 divorce.</textarea>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p1 =  \"\"\"Write a concise summary of the main ideas in article below in bullet-points, don't repeat ideas. article: {BODY}\"\"\".format(BODY=text)\n",
    "\n",
    "display_answer(run_prompt(p1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3> Answer - Time to Generate: 2 seconds</h3>\n",
       "    <textarea cols='100' rows=5.2>{'category': 'news', 'explanation': 'This is a news article about the death of Richard Romanus, an actor known for his role in Mean Streets. The article includes information about his life, career, and family. It also includes quotes from people who knew him and a description of his iconic scene in Mean Streets.'}</textarea>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p2 =  \"\"\"How would you categorized the following text? Is it news article, blog, research paper? \n",
    "Answer JSON following this format: {{'category': 'news', 'explanation': 'text of the article'}}.\n",
    "Text: {BODY}\n",
    "JSON:\"\"\".format(BODY=text)\n",
    "\n",
    "display_answer(run_prompt(p2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3> Answer - Time to Generate: 1 seconds</h3>\n",
       "    <textarea cols='100' rows=2.9>\n",
       "- Soft launch is a strategy where a game is released to a limited number of players before it is released worldwide, usually by releasing only to specific countries</textarea>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p3 =  \"\"\"Summarizes the article in multiple bullet-points. The number of bullet points must below six. article: {BODY}\"\"\".format(BODY=text)\n",
    "p3_answer = run_prompt(p3)\n",
    "display_answer(p3_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bed, Llama listen to me :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expirement 2: System Message\n",
    "\n",
    "The Llama paper describe the system message that uses to set the stage and concext for the model. \n",
    "In the following example, I am using the system messsage. Let see what is the different between P3 that doesn't have system message and P4 that use system message.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3> Answer - Time to Generate: 3 seconds</h3>\n",
       "    <textarea cols='100' rows=9.8>\n",
       "\n",
       "[\n",
       "{\"1\", \"Richard Romanus, actor known for his role in Mean Streets, has died at 80\"},\n",
       "{\"2\", \"Born in Barre, Vermont, and raised in West Hartford, Connecticut, Romanus studied acting with Lee Strasberg at Carnegie Hall\"},\n",
       "{\"3\", \"Romanus had a notable scene with Robert De Niro in Mean Streets, which was filmed on the next-to-last day of shooting\"},\n",
       "{\"4\", \"After Mean Streets, Romanus appeared in various TV shows and films, including Strike Force, Hill Street Blues, and The A-Team\"},\n",
       "{\"5\", \"Romanus was an author and wrote two novels set in Greece, where he lived with his second wife, Oscar-nominated costume designer Anthea Sylbert\"}\n",
       "]</textarea>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p4 = \"\"\"<s>[INST] <<SYS>>\n",
    "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  \n",
    "Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. \n",
    "Please ensure that your responses are socially unbiased and positive in nature.\n",
    "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. \n",
    "If you don't know the answer to a question, please don't share false information.\n",
    "<</SYS>>\n",
    "Write a concise TL;DR summary in numeric bullet-points for the following article. Only include bullet-points. \n",
    "Limit the number of bullet-point to five. Output the answer in JSON format [{{\"1\", bullet-point}}, {{\"2\", bullet-point}}, ...]\n",
    "\n",
    "article: {BODY}\"\"\".format(BODY=text)\n",
    "\n",
    "# p4_answer = run_prompt(p4)\n",
    "# display_answer(p4_answer, \"P4 - With System Message\")\n",
    "# Display p3 too for comparision. \n",
    "\n",
    "display_answer(run_prompt(p4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both P3 and P4 are pretty good and it's hard to see the different the the system message added. I personally prefer P4 (system message) because the answer read a better in my opinion, but I am sure someone will argue with on that. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expirence 3: Modify the System Message\n",
    "The system message can be modified to better fit to the task and define the persona and context we want Llama to assume. \n",
    "\n",
    "Changes applied to the original system message:\n",
    "- Use the researcher persona and specify the tasks to summarizing articles. \n",
    "- Remove safety instruction, there are not needed since we asking Llama to be truthful to the article. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3> Answer - Time to Generate: 3 seconds</h3>\n",
       "    <textarea cols='100' rows=3.7>A soft launch in mobile gaming allows developers to test a game in a real-world environment, on a limited scale, before a global release, helping to improve the game and increase the chances of success at launch.</textarea>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p5 = \"\"\"<s>[INST] <<SYS>>\n",
    "You are a researcher task in summarizing and writing concise brief of articles.  \n",
    "Please ensure that your responses are socially unbiased and positive in nature.\n",
    "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. \n",
    "If you don't know the answer, please don't share false information.\n",
    "<</SYS>>\n",
    "In one sentence, tell me what is the main idea of the following article. Limit the answer to tweenty words. \n",
    "Article: {BODY}\n",
    "[/INST]\"\"\".format(BODY=text)\n",
    "\n",
    "display_answer(run_prompt(p5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The answer for p5 is the best in my opinion so far. I like the into and conclusion that Llama addeed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expirement 4: Asking Questions about the Article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The article is about 'Mobile Game Soft Launch' let ask Llama specific question about it. The answer is pretty good. \n",
    "\n",
    "You are a researcher task with answering questions about an article.  \n",
    "Please ensure that your responses are socially unbiased and positive in nature.\n",
    "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. \n",
    "If you don't know the answer, please don't share false information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3> Answer - Time to Generate: 3 seconds</h3>\n",
       "    <textarea cols='100' rows=11.7>\n",
       "The article does not provide information on mobile game soft launch problems. However, it does discuss the career and life of actor Richard Romanus. One problem that Romanus faced early in his career was being typecast as a tough-guy character actor, as seen in his role in Mean Streets. He also experienced tension with co-star Robert De Niro during the filming of that movie. Later, Romanus faced the challenge of finding steady work in television and film, appearing in a variety of shows and movies throughout the 1970s and 1980s, including Strike Force, which was canceled after 20 episodes. Despite these challenges, Romanus had a successful career as an actor and later as a writer and producer.</textarea>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p6 = \"\"\"[INST]\n",
    "You are a researcher task with extracting information from articles.  \n",
    "Please ensure that your responses are socially unbiased and positive in nature.\n",
    "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. \n",
    "If you don't know the answer, please don't share false information.\n",
    "\n",
    "According to the article mobile game soft launch solves what problems? Please include examples from the article in your answer. \n",
    "Answer should include at leat 50 words.\n",
    "Article: {BODY}\n",
    "[/INST]\n",
    "Answer:\n",
    "\"\"\".format(BODY=text)\n",
    "\n",
    "display_answer(run_prompt(p6))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is pretty good, let see if we improve on that. By asking Llama what is the article is about and then use the answer to ask additional questions. \n",
    "Prompt 7, asks Llama to tell what the article is about and then the answer is used to generate a prompt 8 that ask a second question.\n",
    "\n",
    "To make it easy to programmatically use the answer, I asked Llama to output the answer in JSON. Using expirements (that I didn't included here) I descover that Llama need a template and being told to only output valid JSON. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON Answer:\n",
      " {'article_is_about': \"Richard Romanus' Death\"}\n",
      "Richard Romanus' Death\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>Prompt 8 Answer - Time to Generate: 5 seconds</h3>\n",
       "    <textarea cols='100' rows=8.1>The article doesn't directly mention specific problems that Richard Romanus' work solved. However, as an actor, Romanus provided entertainment and artistic expression through his roles in films and TV shows. He helped bring characters to life, such as the loan shark Michael Longo in Mean Streets, who added tension and conflict to the story. Additionally, Romanus' voice work in animated films and his appearances on various TV shows contributed to the diverse range of characters and performances in the entertainment industry.</textarea>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p7 = \"\"\"<s>[INST] <<SYS>>\n",
    "You are a researcher task with answering questions about an article.  \n",
    "Please ensure that your responses are socially unbiased and positive in nature.\n",
    "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. \n",
    "If you don't know the answer, please don't share false information.\n",
    "<</SYS>>\n",
    "Tell me what is the article about in one to three words? \n",
    "Output the answer in JSON in the following format {{\"article_is_about\": answer}}. Only output JSON\n",
    "Article: {BODY}\n",
    "[/INST]\"\"\".format(BODY=text)\n",
    "\n",
    "a7 = run_prompt(p7)\n",
    "json_a7 = json.loads(a7.answer)\n",
    "print(f\"JSON Answer:\\n {json_a7}\")\n",
    "about = json_a7['article_is_about']\n",
    "print(about)\n",
    "\n",
    "\n",
    "p8 = \"\"\"<s>[INST] <<SYS>>\n",
    "You are a researcher task with answering questions about an article.  \n",
    "Please ensure that your responses are socially unbiased and positive in nature.\n",
    "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. \n",
    "If you don't know the answer, please don't share false information.\n",
    "<</SYS>>\n",
    "According to the article, what problems does {{ABOUT}} solves? Give several short examples from the article in your answer. Limit the answer to fifty words.\n",
    "Article: {BODY}\n",
    "Answer:\n",
    "[/INST]\"\"\".format(BODY=text, ABOUT=about)\n",
    "\n",
    "display_answer(run_prompt(p8),'Prompt 8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow this is awesume. We can feed answers into new prompts to refine the information we try to extract. \n",
    "\n",
    "Let try a different question. What industry the article is about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3> Answer - Time to Generate: 1 seconds</h3>\n",
       "    <textarea cols='100' rows=0.9>The article is focus on the mobile game industry.</textarea>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p9 = \"\"\"<s>[INST] <<SYS>>\n",
    "You are a researcher task with answering questions about an article.  \n",
    "Please ensure that your responses are socially unbiased and positive in nature.\n",
    "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. \n",
    "If you don't know the answer, please don't share false information.\n",
    "<</SYS>>\n",
    "Name the industry the article is focus on? Output only the industry name.\n",
    "Article: {BODY}\n",
    "[/INST]\"\"\".format(BODY=text, ABOUT=about)\n",
    "\n",
    "display_answer(run_prompt(p9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that I asked the answer to include only the industry name, but Llama disregarded my request and wrote a sentence. \n",
    "Let see if we can fixed that by asking the answer to be in JSON. It worked!!! \n",
    "\n",
    "Note: I needed to add \"include only valid JSON\" to prevent Llama then adding an explanation.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3> Answer - Time to Generate: 1 seconds</h3>\n",
       "    <textarea cols='100' rows=0.3>{\"industry\": \"Mobile Game\"}</textarea>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p10 = \"\"\"<s>[INST] <<SYS>>\n",
    "You are a researcher task with answering questions about an article.  \n",
    "Please ensure that your responses are socially unbiased and positive in nature.\n",
    "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. \n",
    "If you don't know the answer, please don't share false information.\n",
    "<</SYS>>\n",
    "Name industry the article is focus on? Output only the industry name. Output the answer in JSON, using format {{\"industry\": industry}}.\n",
    "Include only valid JSON.\n",
    "Article: {BODY}\n",
    "[/INST]\"\"\".format(BODY=text)\n",
    "\n",
    "display_answer(run_prompt(p10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let try and trick Llama and ask him what sport is the article focuses on? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3> Answer - Time to Generate: 1 seconds</h3>\n",
       "    <textarea cols='100' rows=2.6>{\"sport\": \"Not applicable\", \"explanation\": \"The article does not focus on a specific sport. It discusses best practices for launching a mobile game, including soft launch strategies.\"}</textarea>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p11 = \"\"\"[INST]\n",
    "You are a researcher task with answering questions about an article.  \n",
    "Please ensure that your responses are socially unbiased and positive in nature.\n",
    "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. \n",
    "If you don't know the answer, please don't share false information.\n",
    "\n",
    "Name sport the article is focus on? Output only the sport name. Output the answer in JSON, using format {{\"sport\": sport, \"explanation\": explanation}}. \n",
    "Include only valid JSON. Make sure to close the JSON object with a curly bracket.\n",
    "Article: {BODY}\n",
    "[/INST]\"\"\".format(BODY=text)\n",
    "\n",
    "display_answer(run_prompt(p11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3> Answer - Time to Generate: 4 seconds</h3>\n",
       "    <textarea cols='100' rows=23.1>[\n",
       "{\"name\": \"soft launch\", \"type\": \"mobile game development strategy\", \"explanation\": \"A strategy for releasing a game to a limited number of players before it is released worldwide, usually by releasing only to specific countries. This allows developers to test different aspects of the game, such as the gameplay, graphics, and economy in a real-world environment without the pressure of a full release.\"},\n",
       "{\"name\": \"mobile game\", \"type\": \"type of game\", \"explanation\": \"A game designed to be played on mobile devices like smartphones and tablets.\"},\n",
       "{\"name\": \"game studios\", \"type\": \"company\", \"explanation\": \"Companies that develop and publish video games.\"},\n",
       "{\"name\": \"players\", \"type\": \"game stakeholder\", \"explanation\": \"Individuals who play mobile games.\"},\n",
       "{\"name\": \"Apple App Store\", \"type\": \"mobile app marketplace\", \"explanation\": \"A digital distribution platform for mobile apps on iOS devices.\"},\n",
       "{\"name\": \"Google Play Store\", \"type\": \"mobile app marketplace\", \"explanation\": \"A digital distribution platform for mobile apps on Android devices.\"},\n",
       "{\"name\": \"alpha\", \"type\": \"soft launch stage\", \"explanation\": \"The earlier stage of soft launch, used to test the core of the game, including the technology and core gameplay loop.\"},\n",
       "{\"name\": \"beta\", \"type\": \"soft launch stage\", \"explanation\": \"The later stage of soft launch, used to test the meta gameplay loop, marketing acquisition, server scalability, and monetization.\"},\n",
       "{\"name\": \"retention\", \"type\": \"game metric\", \"explanation\": \"The percentage of players who continue to play a game over a certain period of time.\"},\n",
       "{\"name\": \"monetization\", \"type\": \"game metric\", \"explanation\": \"The process of generating revenue from a game, typically through in-app purchases or advertising.\"}\n",
       "]</textarea>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p12 = \"\"\"<s>[INST] <<SYS>>\n",
    "You are a researcher task with answering questions about an article.  \n",
    "Please ensure that your responses are socially unbiased and positive in nature.\n",
    "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. \n",
    "If you don't know the answer, please don't share false information.\n",
    "\n",
    "Output answer in JSON using the following format: {{\"name\": name, \"type\": type, \"explanation\": explanation}}\n",
    "<</SYS>>\n",
    "\n",
    "What entities mentioned in the article that can generalize the topic? [/INST] \n",
    "[\n",
    "{{\"name\": \"semiconductor\", \"type\": \"industry\", \"explanation\": \"Companies engaged in the design and fabrication of semiconductors and semiconductor devices\"}},\n",
    "{{\"name\": \"NBA\", \"type\": \"sport league\", \"explanation\": \"NBA is the national basketball league\"}},\n",
    "{{\"name\": \"Ford F150\", \"type\": \"vehicle\", \"explanation\": \"Article talks about the Ford F150 truck\"}},\n",
    "] </s>\n",
    "\n",
    "<s>[INST]   \n",
    "What entities mentioned are important to the article subject? Limit the answert to ten most important entities. \n",
    "Output answer in JSON using the following format: {{\"name\": name, \"type\": type, \"explanation\": explanation}}\n",
    "Article: {BODY}\n",
    "[/INST]\"\"\".format(BODY=text)\n",
    "\n",
    "display_answer(run_prompt(p12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3> Answer - Time to Generate: 8 seconds</h3>\n",
       "    <textarea cols='100' rows=25.6>{\n",
       "\"oneSentenceSummary\" : \"Richard Romanus, actor known for his role in Mean Streets, dies at 80.\",\n",
       "\"summaryInNumericBulletPoints\": [\n",
       "\"1. Richard Romanus, an actor known for his role in Mean Streets, died at 80.\",\n",
       "\"2. Romanus was born in Barre, Vermont and raised in West Hartford, Connecticut.\",\n",
       "\"3. He graduated from Xavier University in Cincinnati in 1964 with a degree in philosophy.\",\n",
       "\"4. Romanus appeared in various TV shows and films in the 70s and 80s, including Mission: Impossible, The Mod Squad, Night Chase, and Mean Streets.\",\n",
       "\"5. He was married to actress-singer Tina Bohlmann from 1967 to 1975 and to Oscar-nominated costume designer Anthea Sylbert since 1985.\",\n",
       "\"6. In 2011, he published a book about his experience in the theater, Act III: A Small Island in the Aegean.\"\n",
       "],\n",
       "\"entities\": [\n",
       "{\"name\": \"Richard Romanus\", \"type\": \"person\", \"explanation\": \"Actor known for his role in Mean Streets\"},\n",
       "{\"name\": \"Barre, Vermont\", \"type\": \"location\", \"explanation\": \"Birthplace of Richard Romanus\"},\n",
       "{\"name\": \"West Hartford, Connecticut\", \"type\": \"location\", \"explanation\": \"Childhood home of Richard Romanus\"},\n",
       "{\"name\": \"Xavier University\", \"type\": \"educational institution\", \"explanation\": \"University where Richard Romanus graduated with a degree in philosophy\"},\n",
       "{\"name\": \"Mission: Impossible\", \"type\": \"TV show\", \"explanation\": \"TV show where Richard Romanus appeared in the 70s\"},\n",
       "{\"name\": \"The Mod Squad\", \"type\": \"TV show\", \"explanation\": \"TV show where Richard Romanus appeared in the 70s\"},\n",
       "{\"name\": \"Night Chase\", \"type\": \"TV movie\", \"explanation\": \"TV movie where Richard Romanus appeared in the 70s\"},\n",
       "{\"name\": \"Mean Streets\", \"type\": \"movie\", \"explanation\": \"Movie where Richard Romanus had a prominent role in the 70s\"},\n",
       "{\"name\": \"Tina Bohlmann\", \"type\": \"person\", \"explanation\": \"First wife of Richard Romanus\"},\n",
       "{\"name\": \"Anthea Sylbert\", \"type\": \"person\", \"explanation\": \"Second wife of Richard Romanus and Oscar-nominated costume designer\"}\n",
       "]\n",
       "}</textarea>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p13 = \"\"\"<s>[INST] <<SYS>>\n",
    "You are a researcher task with answering questions about an article.  \n",
    "Please ensure that your responses are socially unbiased and positive in nature.\n",
    "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. \n",
    "If you don't know the answer, please don't share false information.\n",
    "\n",
    "<</SYS>>\n",
    "\n",
    "Answers output must confirm to the this JSON format [/INST] \n",
    "\n",
    "JSON Output: {{\n",
    "\"oneSentenceSummary\" : \"Mobile game soft launch is a process of releasing a game to a limited audience for testing.\",\n",
    "\"summaryInNumericBulletPoints\" : [\n",
    "\"1. Mobile game soft launch is a process of releasing a game to a limited audience for testing.\",\n",
    "\"2. Mobile game soft launch is a process of releasing a game to a limited audience for testing.\",\n",
    "]\n",
    "\"entities : [\n",
    "{{\"name\": \"semiconductor\", \"type\": \"industry\", \"explanation\": \"Companies engaged in the design and fabrication of semiconductors and semiconductor devices\"}},\n",
    "{{\"name\": \"NBA\", \"type\": \"sport league\", \"explanation\": \"NBA is the national basketball league\"}},\n",
    "{{\"name\": \"Ford F150\", \"type\": \"vehicle\", \"explanation\": \"Article talks about the Ford F150 truck\"}},\n",
    "]\n",
    "}} </s>\n",
    "\n",
    "<s>[INST]\n",
    "Use the examples above to answer the following question.\n",
    "1. Summarize the article in one sentence. Limit the answer to twenty words.\n",
    "2. Summarize the article in multiple bullet-points. Each bullet-point need to have betweeen ten to tweenty words. Limit the number of bullet points must below six.\n",
    "3. Identify ten entities (companies, people, location, products....) mentioned in the article. Include short explanation for each entity.\n",
    "\n",
    "Use the JSON format above to output your answer. Only output valid JSON format.\n",
    "Article: {BODY}\n",
    "[/INST]\"\"\".format(BODY=text)\n",
    "\n",
    "display_answer(run_prompt(p13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"~/Projects/icognition-backend/tests/data/\"\n",
    "\n",
    "def read_txt_files(directory):\n",
    "    txt_files = []\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith(\".txt\"):\n",
    "            file_path = os.path.join(directory, file)\n",
    "            with open(file_path, \"r\") as f:\n",
    "                txt_files.append(f.read())\n",
    "    return txt_files"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
